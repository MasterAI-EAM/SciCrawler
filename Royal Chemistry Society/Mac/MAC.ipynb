{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Set Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Path to the JSON file containing DOIs\n",
    "json_file_path = ''\n",
    "\n",
    "# Output path for downloaded HTML files\n",
    "output_path = ''\n",
    "\n",
    "# Load DOIs from the JSON file\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file_obj:\n",
    "    dois_data = json.load(file_obj)\n",
    "\n",
    "# Set up Chrome options\n",
    "options = Options()\n",
    "options.add_argument('--user-data-dir=path/to/your/user-data')\n",
    "\n",
    "# Set Chrome driver path\n",
    "chrome_driver_path = '.../chromedriver'\n",
    "\n",
    "# Initialize the Chrome WebDriver using Service and Chrome options\n",
    "service = Service(executable_path=chrome_driver_path, chrome_options=chrome_options)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Keep track of already downloaded indices\n",
    "already_downloaded_indices = set()\n",
    "\n",
    "# Check existing files in the output path\n",
    "existing_files = os.listdir(output_path)\n",
    "for existing_file in existing_files:\n",
    "    try:\n",
    "        index = int(existing_file.split('_')[1].split('.')[0])\n",
    "        already_downloaded_indices.add(index)\n",
    "    except (ValueError, IndexError):\n",
    "        pass\n",
    "\n",
    "# Iterate through DOIs and download HTML content\n",
    "for i, doi in enumerate(tqdm(dois_data, desc=\"Downloading RSC Papers\")):\n",
    "    if i not in already_downloaded_indices:\n",
    "        try:\n",
    "            # Extract the last part of the DOI to use in the search URL\n",
    "            doi_suffix = doi.split(\"/\")[-1]\n",
    "            \n",
    "            # Transform the DOI suffix into the RSC search URL format\n",
    "            search_url = f'https://pubs.rsc.org/en/results?searchtext={doi_suffix}'\n",
    "\n",
    "            # Open the search URL in Chrome\n",
    "            driver.get(search_url)\n",
    "            time.sleep(3)  # Wait for the search results page to load\n",
    "\n",
    "            # Find all links on the page\n",
    "            links = driver.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "            # Check each link for the presence of \"articlehtml\" in its href attribute\n",
    "            html_link = None\n",
    "            for link in links:\n",
    "                if 'articlehtml' in link.get_attribute('href'):\n",
    "                    html_link = link\n",
    "                    break\n",
    "\n",
    "            if html_link is not None:\n",
    "                # Extract the URL from the href attribute\n",
    "                html_url = html_link.get_attribute('href')\n",
    "\n",
    "                # Open the HTML URL in Chrome\n",
    "                driver.get(html_url)\n",
    "                time.sleep(3)  # Wait for the HTML content to load\n",
    "\n",
    "                # Get the HTML source and save it to a file with the DOI as the filename\n",
    "                doi_filename = doi_suffix.replace(\"/\", \"-\")\n",
    "                output_file_path = os.path.join(output_path, f'{doi_filename}.html')\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(driver.page_source)\n",
    "\n",
    "                # Add the index to the set of downloaded indices\n",
    "                already_downloaded_indices.add(i)\n",
    "            else:\n",
    "                print(f'Error: HTML link not found for paper with DOI {doi}')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error downloading paper with DOI {doi}: {str(e)}')\n",
    "\n",
    "# Close the Chrome WebDriver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
