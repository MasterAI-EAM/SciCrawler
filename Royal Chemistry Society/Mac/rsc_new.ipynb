{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "output_base_folder = ''\n",
    "os.makedirs(output_base_folder, exist_ok=True)\n",
    "\n",
    "def gather_existing_dois(output_folder):\n",
    "    existing_dois = set()\n",
    "    for root, dirs, files in os.walk(output_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".html\"):\n",
    "                doi = file.replace(\".html\", \"\").replace(\"-\", \"/\")\n",
    "                existing_dois.add(doi)\n",
    "    return existing_dois\n",
    "\n",
    "async def extract_dois_from_folder(folder_path):\n",
    "    dois_list = []\n",
    "    # Find all JSON files in the specified folder and subfolders\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Load DOIs from each JSON file\n",
    "                with open(file_path, 'r', encoding='utf-8') as file_obj:\n",
    "                    data = json.load(file_obj)\n",
    "                    # Extracting DOIs from the JSON file\n",
    "                    for doi in data.keys():\n",
    "                        dois_list.append((root, doi))  # Append tuple of (root, doi)\n",
    "    return dois_list\n",
    "\n",
    "async def download_rsc(dois_with_root, output_base_folder, input_folder):\n",
    "    # Set up Chrome WebDriver\n",
    "    chrome_driver_path = 'path to /chromedriver.exe'\n",
    "    service = Service(executable_path=chrome_driver_path)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    # Get existing DOIs to avoid re-downloading\n",
    "    existing_dois = gather_existing_dois(output_base_folder)\n",
    "\n",
    "    # Iterate through DOIs and perform actions\n",
    "    for root, doi_data in tqdm(dois_with_root, desc=\"Downloading RSC Papers\"):\n",
    "        doi_filename = doi_data.replace(\"/\", \"-\")\n",
    "\n",
    "        # Skip if the DOI already exists in the output folder\n",
    "        if doi_data in existing_dois:\n",
    "            print(f'Skipping DOI {doi_data} as it already exists.')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            doi_suffix = doi_data.split(\"/\")[-1]\n",
    "            search_url = f'https://pubs.rsc.org/en/results?searchtext={doi_suffix}'\n",
    "            driver.get(search_url)\n",
    "            time.sleep(3)  # Wait for the search results page to load\n",
    "\n",
    "            # Check if the page is showing \"Aw, Snap!\" error message\n",
    "            if \"Aw, Snap!\" in driver.page_source:\n",
    "                print(\"Page is showing 'Aw, Snap!' error message. Refreshing the page...\")\n",
    "                driver.refresh()\n",
    "                time.sleep(3)  # Wait for the page to refresh\n",
    "                continue  # Skip the rest of the loop iteration\n",
    "\n",
    "            links = driver.find_elements(By.TAG_NAME, 'a')\n",
    "            html_link = None\n",
    "            for link in links:\n",
    "                if 'articlehtml' in link.get_attribute('href'):\n",
    "                    html_link = link\n",
    "                    break\n",
    "\n",
    "            if html_link is not None:\n",
    "                html_url = html_link.get_attribute('href')\n",
    "                driver.get(html_url)\n",
    "                time.sleep(3)  # Wait for the HTML content to load\n",
    "\n",
    "                # Determine the subfolder within the output base folder\n",
    "                subfolder = os.path.relpath(root, input_folder)\n",
    "                output_subfolder = os.path.join(output_base_folder, subfolder)\n",
    "                os.makedirs(output_subfolder, exist_ok=True)\n",
    "                output_file_path = os.path.join(output_subfolder, f'{doi_filename}.html')\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(driver.page_source)\n",
    "\n",
    "                # Add the newly downloaded DOI to the existing DOIs set\n",
    "                existing_dois.add(doi_data)\n",
    "            else:\n",
    "                print(f'Error: HTML link not found for paper with DOI {doi_data}')\n",
    "        except Exception as e:\n",
    "            print(f'Error downloading paper with DOI {doi_data}: {str(e)}')\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# Specify the path to the subfolder containing JSON files\n",
    "input_folder = ''\n",
    "\n",
    "# Extract DOIs from the JSON files within the specified folder\n",
    "dois_with_root = await extract_dois_from_folder(input_folder)\n",
    "\n",
    "# Call the function with appropriate arguments\n",
    "await download_rsc(dois_with_root, output_base_folder, input_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
